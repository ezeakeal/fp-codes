{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux\n",
    "\n",
    "### Word Count\n",
    "\n",
    "Write a bash script to calculate the frequency of each word in a text file.\n",
    "For example if a file has the following content\n",
    "\n",
    "```\n",
    "The quick brown fox jumped over the lazy dog.\n",
    "Then the dish ran away with the spoon.\n",
    "\n",
    "```\n",
    "\n",
    "Your script should output:\n",
    "\n",
    "```\n",
    "The 1\n",
    "quick 1\n",
    "brown 1\n",
    "fox 1\n",
    "jumped 1\n",
    "over 1\n",
    "the 3\n",
    "lazy 1\n",
    "dog 1\n",
    "Then 1\n",
    "dish 1\n",
    "ran 1\n",
    "away 1\n",
    "with 1\n",
    "spoon 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment\n",
    "* Developed with Bash in a jupyter notebook... because at this point I am hoping to keep solutions consistent\n",
    "\n",
    "### Thought process\n",
    "* uniq maybe with sort?\n",
    "* will google that\n",
    "* Getting the exact output is very tricky! Made a few mistakes with `cat $file | .. | .. | .. > $file` making empty files\n",
    "\n",
    "#### Attempt 1\n",
    "`cat $file_name | tr ' ' '\\n' | sort | uniq -c`\n",
    "* `cat` - output content of file\n",
    "* `tr ' ' '\\n'` - translate/convert space to newline (so sort picks it up)\n",
    "* `sort` - get repeated words together for uniq\n",
    "* `uniq -c` - reduce list to unique values with their count\n",
    "\n",
    "#### Attempt 2\n",
    "`cat $file_name | tr -d '.' | tr ' ' '\\n' | sort | uniq -c`\n",
    "* `cat` - output content of file\n",
    "* `tr -d '.'` - Remove '.' from file content\n",
    "* `tr ' ' '\\n'` - translate/convert space to newline (so sort picks it up)\n",
    "* `sort` - get repeated words together for uniq\n",
    "* `uniq -c` - reduce list to unique values with their count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File Content:\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "Then the dish ran away with the spoon.\n",
      "\n",
      "Word Frequency:\n",
      "      1 away\n",
      "      1 brown\n",
      "      1 dish\n",
      "      1 dog.\n",
      "      1 fox\n",
      "      1 jumped\n",
      "      1 lazy\n",
      "      1 over\n",
      "      1 quick\n",
      "      1 ran\n",
      "      1 spoon.\n",
      "      3 the\n",
      "      1 The\n",
      "      1 Then\n",
      "      1 with\n",
      "\n",
      "Please remove 'words_test.txt' from '/home/dvagg/Desktop/FlashPointCode'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "####################\n",
    "# Attempt 1\n",
    "####################\n",
    "\n",
    "file_name=words_test.txt\n",
    "truncate -s 0 $file_name\n",
    "\n",
    "echo -e \"The quick brown fox jumped over the lazy dog.\\\n",
    "\\nThen the dish ran away with the spoon.\" >> $file_name\n",
    "\n",
    "echo -e \"\\nFile Content:\"\n",
    "cat $file_name\n",
    "\n",
    "echo -e \"\\nWord Frequency:\"\n",
    "cat $file_name | tr ' ' '\\n' | sort | uniq -c \n",
    "\n",
    "# Cleanup\n",
    "echo -e \"\\nPlease remove '$file_name' from '$(pwd)'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File Content:\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "Then the dish ran away with the spoon.\n",
      "\n",
      "Word frequency..\n",
      "      1 away\n",
      "      1 brown\n",
      "      1 dish\n",
      "      1 dog\n",
      "      1 fox\n",
      "      1 jumped\n",
      "      1 lazy\n",
      "      1 over\n",
      "      1 quick\n",
      "      1 ran\n",
      "      1 spoon\n",
      "      3 the\n",
      "      1 The\n",
      "      1 Then\n",
      "      1 with\n",
      "\n",
      "Please remove 'words_test.txt' from '/home/dvagg/Desktop/FlashPointCode'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "####################\n",
    "# Attempt 2\n",
    "####################\n",
    "\n",
    "file_name=words_test.txt\n",
    "truncate -s 0 $file_name\n",
    "\n",
    "echo -e \"The quick brown fox jumped over the lazy dog.\\\n",
    "\\nThen the dish ran away with the spoon.\" >> $file_name\n",
    "\n",
    "echo -e \"\\nFile Content:\"\n",
    "cat $file_name\n",
    "\n",
    "echo -e \"\\nWord frequency..\"\n",
    "cat $file_name | tr -d '.' | tr ' ' '\\n' | sort | uniq -c\n",
    "\n",
    "# Cleanup\n",
    "echo -e \"\\nPlease remove '$file_name' from '$(pwd)'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution (messy, but matches output)\n",
    "```\n",
    "cat $file_name | tr -d '.' | tr ' ' '\\n' > $file_name_words\n",
    "for word in $(cat -n wordsep_test.txt | sort -k2 -k1n  | uniq -f1 | sort -nk1,1 | cut -f2-); do\n",
    "    echo $(grep \"$word$\" $file_name_words | uniq -c | awk '{print $2,$1}') \n",
    "done\n",
    "```\n",
    "* Make a new file from original with all words on separate lines (with . removed)\n",
    "* for word in (Remove duplicate lines but maintain order)\n",
    "    * `grep` the word from original file and get `uniq -c` so that we have the format we want \n",
    "    * It's only ever N of the same, but 'uniq -c' gives us desired output in one go, then we use awk to switch order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File Content:\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "Then the dish ran away with the spoon.\n",
      "\n",
      "Frequency:\n",
      "The 1\n",
      "quick 1\n",
      "brown 1\n",
      "fox 1\n",
      "jumped 1\n",
      "over 1\n",
      "the 3\n",
      "lazy 1\n",
      "dog 1\n",
      "Then 1\n",
      "dish 1\n",
      "ran 1\n",
      "away 1\n",
      "with 1\n",
      "spoon 1\n",
      "\n",
      "Please remove 'words_test.txt' and 'wordsep_test.txt' from '/home/dvagg/Desktop/FlashPointCode'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "####################\n",
    "# Attempt 3\n",
    "# Rough solution\n",
    "####################\n",
    "\n",
    "file_name=words_test.txt\n",
    "file_name_words=wordsep_test.txt\n",
    "truncate -s 0 $file_name\n",
    "truncate -s 0 $file_name_words\n",
    "\n",
    "echo -e \"The quick brown fox jumped over the lazy dog.\\\n",
    "\\nThen the dish ran away with the spoon.\" >> $file_name\n",
    "\n",
    "echo -e \"\\nFile Content:\"\n",
    "cat $file_name\n",
    "\n",
    "echo -e \"\\nFrequency:\"\n",
    "# First separate the lines into words (removing '.')\n",
    "cat $file_name | tr -d '.' | tr ' ' '\\n' > $file_name_words\n",
    "# For every word in that file (remove duplicate lines, but maintain order)\n",
    "for word in $(cat -n $file_name_words | sort -k2 -k1n  | uniq -f1 | sort -nk1,1 | cut -f2-); do\n",
    "    grep \"$word$\" $file_name_words | uniq -c | awk '{print $2,$1}' # It's only ever N of the same, but 'uniq -c' gives us desired output in one go \n",
    "done\n",
    "\n",
    "# Cleanup\n",
    "echo -e \"\\nPlease remove '$file_name' and '$file_name_words' from '$(pwd)'\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
