{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "## String Compression\n",
    "\n",
    "Uniquely Encode a string to as short a length as possible then decode it. Feel free to look up\n",
    "established algorithms to attempt the shortest length possible, but cite the algorithm you have\n",
    "chosen. We will compare your compression against Run Length Encoding, listed next to each\n",
    "example is the length of the compressed string using Run Length Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment\n",
    "* Developed with Python 3.5.5, installed via Anaconda\n",
    "\n",
    "### Thought process\n",
    "* Don't know of any compression algorithms off the top of my head, will research\n",
    "* Compression depends on the type of data and purpose. We have random data (dictionary/pattern compression is out) and we can't accept lossy compression.\n",
    "* 'smaz' had come up in some searches for text compression algorithms, but it is incorporating some dictionary/pattern based compression, so I am not going further with that for now. https://github.com/antirez/smaz/blob/master/smaz.c\n",
    "* Read: https://marknelson.us/posts/2012/10/09/the-random-compression-challenge-turns-ten.html\n",
    "* Read: https://en.wikipedia.org/wiki/Run-length_encoding \n",
    "    * Haven't seen the phrase, but the concept is simple and intuitive - would be an initial stab at compression. The idea of using double characters to denote a run or repetition of a character is a decent improvement (useful for the random strings, but 0 compression if the characters don't repeat anywhere)\n",
    "    * A quick check of the guessed results of RLE shows that the first string used 47 characters... weird\n",
    "    * Going to grab a RLE Python implementation and see if the results match \n",
    "    * See 'TEST 1'\n",
    "* After reading around, compressing random data may not be something that's possible.. truly random anyway. Patterns can be found, but I can't copy and paste a bunch of patterns from existing algorithms and pass it off as my own.\n",
    "* I could use existing patterns.. and pi exists..\n",
    "\n",
    "#### Dumb idea - \"pi compression\"\n",
    "* Encoding:\n",
    "    * With PI in binary, represent each 8 bits as a byte. \n",
    "    * Find the exact input string within the binary representation. \n",
    "    * Return the location of the string and number of bytes to read.\n",
    "* Decoding:\n",
    "    * Straightforward!\n",
    "* Issue:\n",
    "    * I have a suspicion that as the string gets more complex, the search time is going to approach \"I am never going to hire this guy in a million years, and even then the search may take longer\".\n",
    "* Potential mitigation:\n",
    "    * If there was an evolving index recording where certain patterns or beginnings of patterns existed, that could help the search time. Interesting problem: could you eventually be publicly disclosing source code/passwords?\n",
    "* Issue:\n",
    "    * Every additional character in the string reduces the chance of finding the pattern by 2^8(guess), and will slow down the search by some other factor.\n",
    "    * If the patterns are too complex, could representing the index of the start location in Pi take up more data?\n",
    "* Potential mitigation:\n",
    "    * Break up the incoming string into 8 bytes, followed by a remainder, and return a list of locations to read 8 bytes from, followed by the remainder (uncompressed) to be appended to the result.\n",
    "* Further thinking:\n",
    "    * Googled 'search in pi', found http://angio.net/pi/whynotpi.html, and the odds of finding any NUMBER in the first 200 million digits of pi.\n",
    "* This isn't worth implementing now , even for a demo on small strings\n",
    "* Maybe you could combine partial pattern matching in Pi digits with RLE compression on the masked regions?\n",
    "\n",
    "### More thoughts\n",
    "* Research led to: https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform and https://en.wikipedia.org/wiki/Lyndon_word\n",
    "* Going to test the BWT with RLE\n",
    "* See 'Test 2', results weren't good, BUT:\n",
    "* It's not guaranteed that the data is always random - I can't guarantee random or not - can assume neither..\n",
    "* Found http://www.data-compression.info/Algorithms/BWT/, very cool site but a lot of dead links. There was mention of a \"suffix sorting algorithm\" for BWT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prerequisite imports and declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "try:\n",
    "    from typecheck_magic import typecheck\n",
    "except:\n",
    "    raise Exception(\"Can't import the typecheck magic for Jupyter\")\n",
    "try:\n",
    "    import mypy\n",
    "except ImportError:\n",
    "    raise Exception(\"mypy can't be found, which is required by the typecheck magic, please install it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The solution\n",
    "* Attempt None/RLE/BWT+RLE and return a flag+result for the best compressed data. I don't know anything aobut the data structure going into this compression. I had considered a function that analysed the input BEFORE attempting compression, but that is a rabbit-hole.\n",
    "* Early stage of the rabbit-hole: \n",
    "    * Check how many unique values.. if close to the length, then just return the original string\n",
    "    * If there are fewer unique values, compress\n",
    "        * Randomly sample log(n) characters in n-length string, take substrings of length 3 to test for repeats\n",
    "        * if few repeats found, attempt BWT and retry\n",
    "* Considered using Move To Front transform, but at this point I am in new territory and jumping between ideas that sound good - making implementation slower. Leaving MTF for another time. Heard mention of bijective BWT, another tempting avenue, but have to stop looking at this!\n",
    "    \n",
    "###### Based on\n",
    "* RLE: https://ieeexplore.ieee.org/document/1447423/\n",
    "* BWT: http://www.hpl.hp.com/techreports/Compaq-DEC/SRC-RR-124.pdf (https://marknelson.us/posts/1996/09/01/bwt.html)\n",
    "\n",
    "###### Improvements\n",
    "* Use binary flags to encode what steps were used\n",
    "    * Use the order of the flags to represent the order of the transformations\n",
    "* Include MoveToFront\n",
    "* Potentially include some analysis of the input string for entropy/length and encode using a chain of approaches (which may be toggled following analysis). \n",
    "    * Encode the methods used in a header of the result so result can be decoded correctly. For very large input, would consider sampling the data to help determine compression approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: \u0001\u0003ANBA\u0002A\u0001\u0001\u0011\u0001\u0005\u0001\u0011\n",
      "Decoded: BANANAANANANAANANANAANANANAANANANAANANANA\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "FLAG_RLE = \"\\000\"\n",
    "FLAG_RLE_BWT = \"\\001\"\n",
    "\n",
    "\n",
    "def bwt(s: str) -> str:\n",
    "    \"\"\"Apply Burrows-Wheeler transform to input string.\"\"\"\n",
    "    assert \"\\002\" not in s and \"\\003\" not in s, \"Input string cannot contain STX and ETX characters\"\n",
    "    s = \"\\002\" + s + \"\\003\"  # Add start and end of text marker\n",
    "    table = sorted(s[i:] + s[:i] for i in range(len(s)))  # Table of rotations of string\n",
    "    last_column = [row[-1:] for row in table]  # Last characters of each row\n",
    "    return \"\".join(last_column)  # Convert list of characters into string\n",
    "\n",
    "\n",
    "def ibwt(r: str) -> str:\n",
    "    \"\"\"Apply inverse Burrows-Wheeler transform.\"\"\"\n",
    "    table = [\"\"] * len(r)  # Make empty table\n",
    "    for i in range(len(r)):\n",
    "        table = sorted(r[i] + table[i] for i in range(len(r)))  # Add a column of r\n",
    "    s = [row for row in table if row.endswith(\"\\003\")][0]  # Find the correct row (ending in ETX)\n",
    "    return s.rstrip(\"\\003\").strip(\"\\002\")  # Get rid of start and end markers\n",
    "\n",
    "\n",
    "def rle_enc(string: str) -> str:\n",
    "    # Returns CHARS|COUNTS\n",
    "    # Return it this way because:\n",
    "    #    WW1BBB -> W21B3 -> WWWW...WWWWBBB\n",
    "    # CHARS|COUNTS:\n",
    "    #    WW1BBB -> W1B213 -> WW1BBB\n",
    "    rle_str = rle_cts = \"\"\n",
    "    for c, cgen in groupby(string):\n",
    "        counts = len(list(cgen))\n",
    "        while counts > 0:\n",
    "            rle_str += (c)\n",
    "            rle_cts += chr(counts % 255)\n",
    "            counts -= 255\n",
    "    return rle_str+rle_cts\n",
    "\n",
    "\n",
    "def rle_dec(string: str) -> str:\n",
    "    half_string = int(len(string)/2)\n",
    "    decstr = \"\"\n",
    "    rle_str, rle_cts = string[:half_string], string[half_string:]\n",
    "    for c, chr_counts in zip(rle_str, rle_cts):\n",
    "        counts = ord(chr_counts)\n",
    "        decstr += c * counts\n",
    "    return decstr\n",
    "\n",
    "\n",
    "def encode(string: str) -> str:\n",
    "    # We prepend a flag to our strings to represent how they were compressed\n",
    "    # If the string starts with any of our flags, then we have to use a method with a flag\n",
    "    # Otherwise, we would need a flag to represent non-compressed data, which increases the length!\n",
    "    can_return_minimal = not (string.startswith(FLAG_RLE) or string.startswith(FLAG_RLE_BWT))\n",
    "    # Get RLE and RLE+BWT, and prepend a flag for each so we know how to undo it\n",
    "    rle = FLAG_RLE + rle_enc(string)\n",
    "    rle_bwt = FLAG_RLE_BWT + rle_enc(bwt(string))\n",
    "    # Now get all the strings together\n",
    "    strings = [rle, rle_bwt]\n",
    "    if can_return_minimal:\n",
    "        strings.append(string)\n",
    "    # Sort by length and return the shortest\n",
    "    strings.sort(key = lambda s: len(s))\n",
    "    return strings[0]\n",
    "\n",
    "\n",
    "def decode(string: str) -> str:\n",
    "    if string.startswith(FLAG_RLE):\n",
    "        return rle_dec(string[1:])\n",
    "    elif string.startswith(FLAG_RLE_BWT):\n",
    "        return ibwt(rle_dec(string[1:]))\n",
    "    else:\n",
    "        return string\n",
    "    \n",
    "\n",
    "teststr = \"BANANAANANANAANANANAANANANAANANANAANANANA\"\n",
    "enc = encode(teststr)\n",
    "dec = decode(enc)\n",
    "print(\"Encoded: %s\" % enc)\n",
    "print(\"Decoded: %s\" % decode(enc))\n",
    "assert dec == teststr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'0DE9MDK9J8I1BMUQ18HARUPOKXFE4HLADWV12OYYTUFI59Y1', # 48\n",
      "'6QXXCOLMUNBLYY0WOB5BR2HIR5L5XG02TGRAGV', # 38\n",
      "'5PNL', # 04\n",
      "'GKF8ANZ2DH6P3B5WWFMELX8XEMRSJGKHMDN932EZTM2O', # 44\n",
      "'4ZILNB9DW3Y65GIG4Z5WWICIJN6H7HTU88', # 34\n",
      "'Aaaaahhhhhhmmmmmmmuiiiiiiiaaaaaa', # 15\n",
      "'WWWWWWWWWWWWBWWWWWWWWWWWWBBBWWWWWWWWWWWWWWWWWWWWWWWWBWWWWWWWWWWWWWW', # 15\n",
      "'BANANAANANANAANANANAANANANAANANANAANANANA', # 15\n"
     ]
    }
   ],
   "source": [
    "strings = [\n",
    "    '0DE9MDK9J8I1BMUQ18HARUPOKXFE4HLADWV12OYYTUFI59Y1', # 47\n",
    "    '6QXXCOLMUNBLYY0WOB5BR2HIR5L5XG02TGRAGV', # 36\n",
    "    '5PNL', # 4\n",
    "    'GKF8ANZ2DH6P3B5WWFMELX8XEMRSJGKHMDN932EZTM2O', # 43\n",
    "    '4ZILNB9DW3Y65GIG4Z5WWICIJN6H7HTU88', # 32\n",
    "    'Aaaaahhhhhhmmmmmmmuiiiiiiiaaaaaa', # 12\n",
    "    'WWWWWWWWWWWWBWWWWWWWWWWWWBBBWWWWWWWWWWWWWWWWWWWWWWWWBWWWWWWWWWWWWWW', # 14\n",
    "    'BANANAANANANAANANANAANANANAANANANAANANANA'\n",
    "]\n",
    "\n",
    "for string in strings:\n",
    "    print(\"'%s', # %02d\" % (string, len(encode(string))))\n",
    "    assert decode(encode(string)) == string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length[17], Aaa4hh6mm7uii7aa6\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# TEST 1\n",
    "###########\n",
    "# Found on rosetta code while looking for a basic RLE implementation, could make one, but trying to save time\n",
    "#     http://rosettacode.org/wiki/Run-length_encoding#Python\n",
    "# Interesting - hadn't seen for/else structure before, looked it up, could be handy for cleaner code\n",
    "# I am getting 16 chars, not 14, for something I definitely know can be compressed using RLE\n",
    "# Testing an online example gets the same result: https://www.mathcelebrity.com/runlencode.php\n",
    "# From my understanding, I am pretty sure that 16 characters is the best possible result I can get. \n",
    "# This is likely one of the errors that are mentioned in this exercise, so I won't stress about it. \n",
    "# Maybe some bytes removed by using full 8bits to represent the count, but if the number in bits is interpreted as a letter then we have a problem..\n",
    "# Could store the letters in an array of bytes, then the counts in another array of bytes.. \n",
    "#   this helps only if there are several large repetitions (>9) of characters. Unlikely. \n",
    "\n",
    "def test_encode(input_string):\n",
    "    count = 1\n",
    "    prev = ''\n",
    "    lst = []\n",
    "    for character in input_string:\n",
    "        if character != prev:\n",
    "            if prev:\n",
    "                entry = (prev,count)\n",
    "                lst.append(entry)\n",
    "            count = 1\n",
    "            prev = character\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        try:\n",
    "            entry = (character,count)\n",
    "            lst.append(entry)\n",
    "            return (lst, 0)\n",
    "        except Exception as e:\n",
    "            print(\"Exception encountered {e}\".format(e=e)) \n",
    "            return (e, 1)\n",
    "\n",
    "res, ecode = test_encode(\"Aaaaahhhhhhmmmmmmmuiiiiiiiaaaaaa\")\n",
    "resstr = \"\"\n",
    "for char, rep_count in res:\n",
    "    if rep_count > 1:\n",
    "        resstr += \"%s%s%s\" % (char, char, rep_count)\n",
    "    else:\n",
    "        resstr += char\n",
    "print(\"Length[%s], %s\" % (len(resstr), resstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Length: 48\n",
      "BWT 0DE9MDK9J8I1BMUQ18HARUPOKXFE4HLADWV12OYYTUFI59Y1 --> \u00031\u0002YVQI1EI1JKE5LH10MAFDXU848F9DOH9BP2UUAYTRMWDK9YO\n",
      "RLE Length[48], BWT+RLE Length[98]\n",
      "Decoded: K\u0001Y\u00011\u0001\u0003\u0001\u0002P\u0001O\u0001K\u0001Y\u00011\u0001\u0003\u0001\u0002P\u0001O\u0001K\u0001Y\u00011\u0001\u0003\u0001\u0002P\u0001O\u0001K\u0001Y\u00011\u0001\u0003\u0001\u0002P\u0001O\u0001K\u0001Y\u00011\u0001\u0003\u0001\u0002P\u0001O\u0001K\u0001Y\u00011\u0001\u0003\u0001\u0002P\u0001O\u0001K\u0001Y\u00011\u0001\u0003\u0001\u0002P\u0001O\u0001K\u0001Y\u00011\u0001\n",
      "\n",
      "Original Length: 38\n",
      "BWT 6QXXCOLMUNBLYY0WOB5BR2HIR5L5XG02TGRAGV --> \u0003VGYR0BRL\u0002RON5XXTA2H5OBLUWC6BIG2MG0X5QYL\n",
      "RLE Length[38], BWT+RLE Length[78]\n",
      "Decoded: \u0001\u0003\u0001\u0002C\u0001O\u0001L\u0001M\u0001U\u0001N\u0001B\u0001L\u0002\u00016\u0001Q\u0001Y\u00010\u0001W\u0001O\u0001B\u00015\u0001B\u0001R\u00012\u0001H\u0001I\u0001R\u00015\u0001L\u00015\u0001X\u0001X\u0001G\u00010\u00012\u0001T\u0001G\u0001R\u0001A\u0001G\u0001V\u0001\n",
      "\n",
      "Original Length: 4\n",
      "BWT 5PNL --> \u0003L\u0002NP5\n",
      "RLE Length[4], BWT+RLE Length[12]\n",
      "Decoded: \u0001\u0002\u00015\u0001P\u0001N\u0001L\u0001\n",
      "\n",
      "Original Length: 44\n",
      "BWT GKF8ANZ2DH6P3B5WWFMELX8XEMRSJGKHMDN932EZTM2O --> \u0003OZ3M9PBHFXN832MMX2KW\u0002JDKSGGETHFEDA26MRZW5L8NE\n",
      "RLE Length[44], BWT+RLE Length[88]\n",
      "Decoded: \u0001F\u0001N\u00019\u00013\u00012\u0001E\u0002D\u0001O\u0001\u0003\u0001\u0002K\u0001F\u00018\u0001A\u0001P\u00013\u0001B\u00015\u0001X\u0001E\u0001N\u0002\u0001G\u0001L\u0001Z\u00012\u0001D\u0001H\u0001M\u0001T\u0001M\u0001E\u0001M\u00012\u0001R\u0001W\u0001F\u0001N\u00019\u00013\u00012\u0001E\u0002D\u0001O\u0001\n",
      "\n",
      "Original Length: 34\n",
      "BWT 4ZILNB9DW3Y65GIG4Z5WWICIJN6H7HTU88 --> \u00038WG\u00026ZYNH8UBNI9I567WGCZIIJLHTDW5344\n",
      "RLE Length[34], BWT+RLE Length[68]\n",
      "Decoded: 7\u0001I\u0001D\u0001W\u0001Y\u00016\u0001H\u0001W\u00013\u0002\u00015\u0001H\u00018\u0001\u0003\u0001\u0002Z\u0001L\u0001U\u00019\u0001G\u00014\u0002N\u00017\u0001I\u0001D\u0001W\u0001Y\u00016\u0001H\u0001W\u00013\u0002\u00015\u0001H\u00018\u0001\n",
      "\n",
      "Original Length: 32\n",
      "BWT Aaaaahhhhhhmmmmmmmuiiiiiiiaaaaaa --> \u0003a\u0002aaaaaiAaaaahhhhhiiiiiiuhmmmmmmm\n",
      "RLE Length[15], BWT+RLE Length[24]\n",
      "Decoded: i\u0003\u0001\u0006i\u0001a\u0001m\u0005h\u0005a\u0001\u0007u\u0004h\u0002\u0001A\u0001i\n",
      "\n",
      "Original Length: 67\n",
      "BWT WWWWWWWWWWWWBWWWWWWWWWWWWBBBWWWWWWWWWWWWWWWWWWWWWWWWBWWWWWWWWWWWWWW --> \u0003WWBWWBWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWB\u0002WWWBWWWWWWWWWWB\n",
      "RLE Length[15], BWT+RLE Length[24]\n",
      "Decoded: \u0001B\u0001B\u0001W\u0003\u0001\n",
      "W\u0002-B\u0002B\u0001W\u0001B\u0001B\u0001W\n",
      "\n",
      "Original Length: 41\n",
      "BWT BANANAANANANAANANANAANANANAANANANAANANANA --> \u0003ANNNNNNNNNNNNNNNNNBAAAAA\u0002AAAAAAAAAAAAAAAAA\n",
      "RLE Length[15], BWT+RLE Length[14]\n",
      "Decoded: \u0001A\u0002\u0003\u0001\u0011A\u0001\u0011N\u0001A\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# TEST 2\n",
    "# Code taken from:\n",
    "# https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform\n",
    "# Final thoughts: This could be useful, but I can't assume what the data is likely to be composed of. \n",
    "# Although some strings are compressable, most seem random.\n",
    "###########\n",
    "def bwt(s):\n",
    "    \"\"\"Apply Burrows-Wheeler transform to input string.\"\"\"\n",
    "    assert \"\\002\" not in s and \"\\003\" not in s, \"Input string cannot contain STX and ETX characters\"\n",
    "    s = \"\\002\" + s + \"\\003\"  # Add start and end of text marker\n",
    "    table = sorted(s[i:] + s[:i] for i in range(len(s)))  # Table of rotations of string\n",
    "    last_column = [row[-1:] for row in table]  # Last characters of each row\n",
    "    return \"\".join(last_column)  # Convert list of characters into string\n",
    "\n",
    "def ibwt(r):\n",
    "    \"\"\"Apply inverse Burrows-Wheeler transform.\"\"\"\n",
    "    table = [\"\"] * len(r)  # Make empty table\n",
    "    for i in range(len(r)):\n",
    "        table = sorted(r[i] + table[i] for i in range(len(r)))  # Add a column of r\n",
    "    s = [row for row in table if row.endswith(\"\\003\")][0]  # Find the correct row (ending in ETX)\n",
    "    return s.rstrip(\"\\003\").strip(\"\\002\")  # Get rid of start and end markers\n",
    "\n",
    "for teststr in strings:\n",
    "    r = bwt(teststr)\n",
    "    print(\"\\nOriginal Length: %s\" % len(teststr))\n",
    "    print(\"BWT %s --> %s\" % (teststr, r))\n",
    "    res = rle_enc(r)\n",
    "    print(\"RLE Length[%s], BWT+RLE Length[%s]\" % (len(encode(teststr)), len(res)))\n",
    "    print(\"Decoded: %s\" % ibwt(decode(res)))\n",
    "    assert ibwt(rle_dec(res)) == teststr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
